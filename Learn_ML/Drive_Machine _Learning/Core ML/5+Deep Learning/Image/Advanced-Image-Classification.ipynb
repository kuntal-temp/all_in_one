{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Advanced-Image-Classification.ipynb","provenance":[],"authorship_tag":"ABX9TyPtm1GmKqqYClvRF82q/eEW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Import Dataset\n","\n","folder structer\n","```\n","flower_photo/\n","    daisy/\n","    dandelion/\n","    roses/\n","    sunflowers/\n","    tulips/\n","```"],"metadata":{"id":"JMHIt3c1U7gw"}},{"cell_type":"code","source":["import pathlib\n","dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n","data_dir = pathlib.Path(data_dir)"],"metadata":{"id":"EG5CSbtJuQO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","print(\"all folder names are : \", os.listdir('/root/.keras/datasets/flower_photos/'))\n","all_roses = list(data_dir.glob('roses/*'))\n","one_rose = all_roses[0]\n","print(\"one rose : \", one_rose)"],"metadata":{"id":"afzSbThM0kew","executionInfo":{"status":"ok","timestamp":1641841115651,"user_tz":-330,"elapsed":395,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d610b388-8d43-48bb-f80e-d3c417a0e96e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["all folder names are :  ['sunflowers', 'roses', 'daisy', 'dandelion', 'tulips', 'LICENSE.txt']\n","one rose :  /root/.keras/datasets/flower_photos/roses/15060816740_68e1b2c31b.jpg\n"]}]},{"cell_type":"code","source":["import PIL\n","PIL.Image.open(one_rose)"],"metadata":{"id":"ARrRtYdW2Z7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = PIL.Image.open(one_rose)\n","print(image.format)\n","print(image.size)\n","print(image.mode)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eicbeLkfWTke","executionInfo":{"status":"ok","timestamp":1641841717627,"user_tz":-330,"elapsed":402,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"outputId":"39c8d409-df9e-4311-e67d-de7a2756bc4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["JPEG\n","(159, 240)\n","RGB\n"]}]},{"cell_type":"markdown","source":["# Filter out corrupted images if any"],"metadata":{"id":"3lYMXLU7hrhP"}},{"cell_type":"markdown","source":["# Dimensions Mean for random Image Set"],"metadata":{"id":"wQMpcQIcW9-I"}},{"cell_type":"code","source":["dim1 = []\n","dim2 = []\n","for one_rose in all_roses:\n","    image = PIL.Image.open(one_rose)\n","    d1,d2 = image.size\n","    dim1.append(d1)\n","    dim2.append(d2)\n","\n","x_pix = int(np.mean(dim1) // 1)\n","y_pix = int(np.mean(dim2) // 1)\n","image_shape = (x_pix, y_pix, 3)\n","\n","print(image_shape)"],"metadata":{"id":"dgP-MVyQW6gW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Image Shape & Size"],"metadata":{"id":"vIZTY-bWh20I"}},{"cell_type":"code","source":["batch_size = 32\n","input_shape = image_shape  # (x_pix, y_pix, 3)\n","image_size = (x_pix, y_pix)"],"metadata":{"id":"lXDsXy-SYuLb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate Training & Test\n","\n",">think like data_dir=flower_photos is present in your PWD"],"metadata":{"id":"egjjrhJBh9Kn"}},{"cell_type":"code","source":["\"\"\"\n","tf.keras.utils.image_dataset_from_directory\n","\n","train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n","                                                            shuffle=True,\n","                                                            batch_size=BATCH_SIZE,\n","                                                            image_size=IMG_SIZE)\n","validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n","                                                                 shuffle=True,\n","                                                                 batch_size=BATCH_SIZE,\n","                                                                 image_size=IMG_SIZE)\n","   OR\n","\n","tf.keras.preprocessing.image_dataset_from_directory\n","\"\"\"\n","\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    data_dir,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=42,\n","    image_size=image_size,\n","    batch_size=batch_size\n",")\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    data_dir,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=42,\n","    image_size=image_size,\n","    batch_size=batch_size\n",")"],"metadata":{"id":"sA3XqNmm21nJ","executionInfo":{"status":"ok","timestamp":1641841955200,"user_tz":-330,"elapsed":1020,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b98628d7-a1e3-45d3-b0f0-8f535e425373"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3670 files belonging to 5 classes.\n","Using 2936 files for training.\n","Found 3670 files belonging to 5 classes.\n","Using 734 files for validation.\n"]}]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"id":"QijEIbFf3ZqO","executionInfo":{"status":"ok","timestamp":1641841970469,"user_tz":-330,"elapsed":396,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"480fed41-30e3-4b18-b4eb-f77b9f88e4fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"]}]},{"cell_type":"code","source":["class_names = val_ds.class_names\n","print(class_names)"],"metadata":{"id":"dyNsOrfS3a03","executionInfo":{"status":"ok","timestamp":1641841979523,"user_tz":-330,"elapsed":384,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e442b031-7956-4c26-f76d-ced4821efd61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"]}]},{"cell_type":"markdown","source":["## Display images with class"],"metadata":{"id":"mNcSL5oWt-rt"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for images, labels in train_ds.take(1):  # taking 1st batch\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")"],"metadata":{"id":"mhR7tQIf3gnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_batch, labels_batch in train_ds:\n","    print(image_batch.shape)\n","    print(labels_batch.shape)\n","    break"],"metadata":{"id":"Uc6DHorC34L7","executionInfo":{"status":"ok","timestamp":1641842808768,"user_tz":-330,"elapsed":994,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"227f17f0-cad3-4919-fbfb-91a6a618ec13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 364, 274, 3)\n","(32,)\n"]}]},{"cell_type":"markdown","source":["## Data augmentation\n"," Data augmentation takes the approach of generating additional training data from your existing examples\n","\n","https://www.tensorflow.org/tutorials/images/data_augmentation"],"metadata":{"id":"hvnYR3d9jnCh"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","  [\n","    layers.RandomFlip(\"horizontal\", input_shape=image_shape),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1)\n","  ]\n",")"],"metadata":{"id":"yauSgrJyjRqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Augmented images display"],"metadata":{"id":"KYlltjOanG8y"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for images, _ in train_ds.take(1):\n","  for i in range(9):\n","    augmented_images = data_augmentation(images)\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"],"metadata":{"id":"UWwMYP1jnCjk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### AUTOTUNE"],"metadata":{"id":"Wzfz3ZfCjePo"}},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"KSkbCk8C4Zo7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating CNN"],"metadata":{"id":"r_532FOinWXV"}},{"cell_type":"code","source":["model = models.Sequential([\n","  data_augmentation,\n","  layers.Rescaling(1./255, input_shape=image_shape),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Dropout(0.2),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(len(class_names))\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy']\n",")\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=1,\n","    callbacks=[early_stop]\n",")\n","\n","model.summary()"],"metadata":{"id":"6vRG8ib65AvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(model.history.history).plot()"],"metadata":{"id":"MUpbUDwg6jrc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Image Data Generator\n","\n","folder structer\n","```\n","flower_photo/\n","    train_data/\n","        daisy/\n","        dandelion/\n","        roses/\n","        sunflowers/\n","        tulips/\n","    test_data/\n","        daisy/\n","        dandelion/\n","        roses/\n","        sunflowers/\n","        tulips/\n","```"],"metadata":{"id":"L9PpywZ_q6uF"}},{"cell_type":"code","source":["image_gen = ImageDataGenerator(\n","    rescale=1/255,            # Rescale the image by normalzing it.\n","    rotation_range=20,        # rotate the image 20 degrees\n","    width_shift_range=0.10,   # Shift the pic width by a max of 5%\n","    height_shift_range=0.10,  # Shift the pic height by a max of 5%\n","    shear_range=0.1,          # Shear means cutting away part of the image (max 10%)\n","    zoom_range=0.1,           # Zoom in by 10% max\n","    horizontal_flip=True,     # Allo horizontal flipping\n","    vertical_flip=False,\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    fill_mode='nearest'       # Fill in missing pixels with the nearest filled value\n",")\n","\n","train_image_gen = image_gen.flow_from_directory(\n","    train_data,\n","    target_size=image_size,\n","    color_mode='rgb',\n","    classes=None,\n","    class_mode='categorical',\n","    batch_size=batch_size, shuffle=True,\n","    seed=None, save_to_dir=None, save_prefix='', save_format='png',\n","    follow_links=False, subset=None, interpolation='nearest'\n",")\n","\n","test_image_gen = image_gen.flow_from_directory(\n","    test_data,\n","    target_size=image_size,\n","    color_mode='rgb',\n","    classes=None,\n","    class_mode='categorical',\n","    batch_size=batch_size, shuffle=False,\n","    seed=None, save_to_dir=None, save_prefix='', save_format='png',\n","    follow_links=False, subset=None, interpolation='nearest'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0t4zxrfmhSn","executionInfo":{"status":"ok","timestamp":1641845849992,"user_tz":-330,"elapsed":416,"user":{"displayName":"Kuntal Samanta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmQIdHQwmPKhiStxjoDFgCDfTlLEm6wMLM3_nt=s64","userId":"06445374738296173198"}},"outputId":"ffcf31d0-5761-43c0-d4ba-6425506a5623"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3670 images belonging to 5 classes.\n","Found 3670 images belonging to 5 classes.\n"]}]},{"cell_type":"markdown","source":["## Fit method for Image Generator"],"metadata":{"id":"xJ4V_lnkqd6N"}},{"cell_type":"code","source":["\"\"\"\n","# it does not used now\n","model.fit_generator(\n","    train_image_gen,\n","    validation_data=test_image_gen,\n","    epochs=20,\n","    callbacks=[early_stop],\n","    use_multiprocessing=True\n",")\n","\"\"\"\n","\n","model.fit(\n","    train_image_gen,\n","    validation_data=test_image_gen,\n","    steps_per_epoch=2000,\n","    epochs=50,\n","    validation_steps=800\n",")\n","\n","model.evaluate_generator(test_image_gen)\n","pred_probabilities = model.predict_generator(test_image_gen)\n","predictions = pred_probabilities > 0.5\n","print(classification_report(test_image_gen.classes,predictions))"],"metadata":{"id":"wdLa1mP2qbP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(model.history.history).plot()"],"metadata":{"id":"XN04Dhn9N-_d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict"],"metadata":{"id":"sIqgjjBxro3O"}},{"cell_type":"code","source":["sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n","sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n","\n","img = tf.keras.utils.load_img(sunflower_path, target_size=image_size)\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"],"metadata":{"id":"54iWfPS_rtHz"},"execution_count":null,"outputs":[]}]}