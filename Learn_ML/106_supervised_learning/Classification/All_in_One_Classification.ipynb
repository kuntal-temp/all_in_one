{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe0670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manupulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# impute\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler, PolynomialFeatures\n",
    "\n",
    "# model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, RepeatedKFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# liner_model\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "# svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "# tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10244c73",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e22609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           0           5.1          3.5           1.4          0.2  setosa\n",
       "1           1           4.9          3.0           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../test_data/iris.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03252ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['Unnamed: 0']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a46aa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802e9f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5b596",
   "metadata": {},
   "source": [
    "# x, y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2ec9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd57378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02cc3664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f2254",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6dca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916e0138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640653c",
   "metadata": {},
   "source": [
    "# Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002b42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5, missing_values=np.nan)\n",
    "x[:, :] = imputer.fit_transform(x[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5912323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189c0e1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9700ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4763e8",
   "metadata": {},
   "source": [
    "# Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d250f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train[:, :] = scaler.fit_transform(x_train[:, :])\n",
    "x_test[:, :] = scaler.fit_transform(x_test[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b483958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01827123,  1.2864604 , -1.39338902, -1.3621769 ],\n",
       "       [-0.7730102 ,  2.43545215, -1.33550342, -1.49647603]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da75763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c495d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25621067, -0.71903739,  0.58987181,  0.05585913],\n",
       "       [-0.21299441,  1.61629772, -1.03834577, -1.06789518]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbb31635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5cdb8",
   "metadata": {},
   "source": [
    "# Model Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a562ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(classifier=None, x_train=None, y_train=None, y_test=None, y_pred=None):\n",
    "    # confusion matrix\n",
    "    con_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"confusion matrix = \\n\", con_matrix)\n",
    "\n",
    "    # accuracy score\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score = \", acc_score)\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    print(\"Compare with Predict and actual\\n\", np.concatenate((y_test.reshape(-1,1), y_pred.reshape(-1,1)), 1)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b411d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7bbb374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  0.9736842105263158\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, \n",
    "    'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', \n",
    "    'random_state': 0, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False\n",
    "}\n",
    "classifier = LogisticRegression()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef0002",
   "metadata": {},
   "source": [
    "# Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29c5c4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, \n",
    "          'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, \n",
    "          'probability': False, 'random_state': 0, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74562496",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a804789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  0.9736842105263158\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, \n",
    "    'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None,\n",
    "    'tol': 0.0001, 'verbose': 0\n",
    "}\n",
    "classifier = LinearSVC()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a09b2",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db836864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None,\n",
    "    'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100,\n",
    "    'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False\n",
    "}\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723cd203",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eec2ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None,\n",
    "    'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'\n",
    "}\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb056e0",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20a14225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  0.9736842105263158\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, \n",
    "    'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge',\n",
    "    'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5,\n",
    "    'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0,\n",
    "    'warm_start': False\n",
    "}\n",
    "classifier = SGDClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a698f19",
   "metadata": {},
   "source": [
    "# K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c07fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, \n",
    "    'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'\n",
    "}\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc7eaf",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b403251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  0.9736842105263158\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'priors': None, 'var_smoothing': 1e-09\n",
    "}\n",
    "classifier = GaussianNB()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f1f6e",
   "metadata": {},
   "source": [
    "# XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4269f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:12:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic', 'use_label_encoder': False, 'base_score': None, 'booster': None,\n",
    "    'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, \n",
    "    'enable_categorical': False, 'gamma': None, 'gpu_id': None, 'importance_type': None, \n",
    "    'interaction_constraints': None, 'learning_rate': None, 'max_delta_step': None, 'max_depth': None,\n",
    "    'min_child_weight': None, 'missing': np.nan, 'monotone_constraints': None, 'n_estimators': 100,\n",
    "    'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None,\n",
    "    'reg_lambda': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None,\n",
    "    'validate_parameters': None, 'verbosity': None\n",
    "}\n",
    "classifier = XGBClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5fbfe9",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aaaaddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, \n",
    "    'random_state': None\n",
    "}\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468e542",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4346d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "####################\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('clf1', log_clf), ('clf2', rnd_clf), ('clf3', svm_clf)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(x_train, y_train)\n",
    "y_pred = voting_clf.predict(x_test)\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)\n",
    "\n",
    "print(\"#\"*20)\n",
    "\n",
    "# Example 2\n",
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(x_train, y_train)\n",
    "print(eclf1.predict(x_test))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "eclf2 = eclf2.fit(x_train, y_train)\n",
    "print(eclf2.predict(x_test))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,1,1], flatten_transform=True)\n",
    "eclf3 = eclf3.fit(x_train, y_train)\n",
    "print(eclf3.predict(x_test))\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b5720",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2db2ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'base_estimator': DecisionTreeClassifier(), \n",
    "    'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, \n",
    "    'max_samples': 1.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None,\n",
    "    'verbose': 0, 'warm_start': False\n",
    "}\n",
    "classifier = BaggingClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a757afc",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c8cbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "estimators=[\n",
    "    ('clf1', log_clf), ('clf2', rnd_clf), ('clf3', svm_clf)\n",
    "]\n",
    "classifier = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d49566",
   "metadata": {},
   "source": [
    "# Gradient Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e380a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  0.9736842105263158\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 1.0, 'loss': 'deviance', \n",
    "    'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, \n",
    "    'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, \n",
    "    'n_iter_no_change': None, 'random_state': 0, 'subsample': 1.0, 'tol': 0.0001, \n",
    "    'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False\n",
    "}\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202a25b",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "749d75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "accuracy score =  1.0\n",
      "Compare with Predict and actual\n",
      " [[1 1]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'categorical_features': None, 'early_stopping': 'auto', 'l2_regularization': 0.0, 'learning_rate': 0.1,\n",
    "    'loss': 'auto', 'max_bins': 255, 'max_depth': None, 'max_iter': 100, 'max_leaf_nodes': 31, \n",
    "    'min_samples_leaf': 20, 'monotonic_cst': None, 'n_iter_no_change': 10, 'random_state': None, \n",
    "    'scoring': 'loss', 'tol': 1e-07, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False\n",
    "}\n",
    "classifier = HistGradientBoostingClassifier()\n",
    "classifier.set_params(**params)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print_summary(classifier, x_train, y_train, y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
