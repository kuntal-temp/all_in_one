{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564bb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e74f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data : \n",
      " [[ 9  5 15 18]\n",
      " [14 16  3  6]\n",
      " [ 4  3  1 10]\n",
      " [18 15 14 10]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(1, 20, (4,4))\n",
    "print(\"raw data : \\n\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cfbda",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "\n",
    "\n",
    "## Why do we use standard scaler?\n",
    "StandardScaler removes the mean and scales each feature/variable to unit variance. This operation is performed feature-wise in an independent way. StandardScaler can be influenced by outliers (if they exist in the dataset) since it involves the estimation of the empirical mean and standard deviation of each feature.\n",
    "\n",
    "```class sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)```\n",
    "\n",
    "The standard score of a sample x is calculated as: z = (x - u) / s\n",
    "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False\n",
    "\n",
    "\n",
    "## Why do we use min max scaler?\n",
    "Transform features by scaling each feature to a given range. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
    "\n",
    "\n",
    "## Why do we use maxabsscaler?\n",
    "MaxAbs Scaler: MaxAbsScaler is best suited to scale the sparse data. It scales each feature by dividing it with the largest maximum value in each feature. For example, if an input variable has the original value [2,-1,0,1] then MaxAbs will scale it as [1,-0.5,0,0.5]. It divided each value with the highest value i.e. 2\n",
    "\n",
    "\n",
    "## Should I use MinMaxScaler or StandardScaler?\n",
    "StandardScaler is useful for the features that follow a Normal distribution. Therefore, it makes mean = 0 and scales the data to unit variance.\n",
    "MinMaxScaler may be used when the upper and lower boundaries are well known from domain knowledge. MinMaxScaler preserves the shape of the original distribution. It doesn't meaningfully change the information embedded in the original data. Note that MinMaxScaler doesn't reduce the importance of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecb5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "after StandardScaler transform : \n",
      " [[-0.4276029  -0.81838794  1.07146232  1.60591014]\n",
      " [ 0.52262577  1.07682623 -0.83335958 -1.14707867]\n",
      " [-1.37783158 -1.16297233 -1.1508299  -0.22941573]\n",
      " [ 1.28280871  0.90453403  0.91272716 -0.22941573]]\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler [-1, +1]\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_scale = sc.fit_transform(X)\n",
    "print(\"\\nafter StandardScaler transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11318d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  -2.7755575615628914e-17\n",
      "Max =  1.6059101370939322\n",
      "Min =  -1.3778315806221817\n",
      "Std =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4376dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revert StandardScaler :\n",
      " [[ 9.  5. 15. 18.]\n",
      " [14. 16.  3.  6.]\n",
      " [ 4.  3.  1. 10.]\n",
      " [18. 15. 14. 10.]]\n"
     ]
    }
   ],
   "source": [
    "revert_standardization = sc.inverse_transform(X_scale)\n",
    "print(\"revert StandardScaler :\\n\", revert_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c3da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after MinMaxScaler transform : \n",
      " [[0.35714286 0.15384615 1.         1.        ]\n",
      " [0.71428571 1.         0.14285714 0.        ]\n",
      " [0.         0.         0.         0.33333333]\n",
      " [1.         0.92307692 0.92857143 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler [0, 1]\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_scale = sc.fit_transform(X)\n",
    "print(\"after MinMaxScaler transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957f6c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.4929029304029304\n",
      "Max =  1.0\n",
      "Min =  0.0\n",
      "Std =  0.41315230618238763\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc13d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revert StandardScaler :\n",
      " [[ 9.  5. 15. 18.]\n",
      " [14. 16.  3.  6.]\n",
      " [ 4.  3.  1. 10.]\n",
      " [18. 15. 14. 10.]]\n"
     ]
    }
   ],
   "source": [
    "revert_standardization = sc.inverse_transform(X_scale)\n",
    "print(\"revert StandardScaler :\\n\", revert_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef9a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after MaxAbsScaler transform : \n",
      " [[0.5        0.3125     1.         1.        ]\n",
      " [0.77777778 1.         0.2        0.33333333]\n",
      " [0.22222222 0.1875     0.06666667 0.55555556]\n",
      " [1.         0.9375     0.93333333 0.55555556]]\n"
     ]
    }
   ],
   "source": [
    "# MaxAbsScaler [-1, 1]\n",
    "'''\n",
    "This scaler is meant for data that is already centered at zero or sparse data. \n",
    "It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "'''\n",
    "sc = MaxAbsScaler()\n",
    "\n",
    "X_scale = sc.fit_transform(X)\n",
    "print(\"after MaxAbsScaler transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90a5d1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.5988715277777777\n",
      "Max =  1.0\n",
      "Min =  0.06666666666666667\n",
      "Std =  0.33742005038342393\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa7b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revert StandardScaler :\n",
      " [[ 9.  5. 15. 18.]\n",
      " [14. 16.  3.  6.]\n",
      " [ 4.  3.  1. 10.]\n",
      " [18. 15. 14. 10.]]\n"
     ]
    }
   ],
   "source": [
    "revert_standardization = sc.inverse_transform(X_scale)\n",
    "print(\"revert StandardScaler :\\n\", revert_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4053a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after PowerTransformer transform : \n",
      " [[-0.38044128 -0.70358814  1.02043694  1.42647651]\n",
      " [ 0.54874683  1.03777587 -0.65767331 -1.40173416]\n",
      " [-1.41456211 -1.25616325 -1.29052012 -0.01237117]\n",
      " [ 1.24625655  0.92197552  0.92775649 -0.01237117]]\n"
     ]
    }
   ],
   "source": [
    "# PowerTransformer [Apply a power transform feature wise to make data more Gaussian-like]\n",
    "'''\n",
    "PowerTransformer(method='yeo-johnson', *, standardize=True, copy=True)\n",
    "\n",
    "yeo-johnson => works with positive and negative values\n",
    "box-cox => only works with strictly positive values\n",
    "\n",
    "This is often described as removing skewness in the distribution, although more generally is described \n",
    "as stabilizing the variance of the distribution.\n",
    "'''\n",
    "sc = PowerTransformer()\n",
    "\n",
    "X_scale = sc.fit_transform(X)\n",
    "print(\"after PowerTransformer transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37b34e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  8.326672684688674e-17\n",
      "Max =  1.4264765124294436\n",
      "Min =  -1.4145621072079244\n",
      "Std =  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c4f84",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0042cd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after Normalizer transform : \n",
      " [[0.3516591  0.19536617 0.5860985  0.7033182 ]\n",
      " [0.62798583 0.71769809 0.13456839 0.26913678]\n",
      " [0.35634832 0.26726124 0.08908708 0.89087081]\n",
      " [0.61921882 0.51601569 0.48161464 0.34401046]]\n"
     ]
    }
   ],
   "source": [
    "# normalize [0, 1]\n",
    "nc = Normalizer()\n",
    "\n",
    "X_scale = nc.fit_transform(X)\n",
    "print(\"after Normalizer transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35792857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.44689113195705926\n",
      "Max =  0.8908708063747479\n",
      "Min =  0.0890870806374748\n",
      "Std =  0.22425056561386467\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d231e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after normalize transform : \n",
      " [[0.3516591  0.19536617 0.5860985  0.7033182 ]\n",
      " [0.62798583 0.71769809 0.13456839 0.26913678]\n",
      " [0.35634832 0.26726124 0.08908708 0.89087081]\n",
      " [0.61921882 0.51601569 0.48161464 0.34401046]]\n"
     ]
    }
   ],
   "source": [
    "X_scale = normalize(X, norm='l2')\n",
    "print(\"after normalize transform : \\n\", X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734dd041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.44689113195705926\n",
      "Max =  0.8908708063747479\n",
      "Min =  0.0890870806374748\n",
      "Std =  0.22425056561386467\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean = \", X_scale.mean())\n",
    "print(\"Max = \", X_scale.max())\n",
    "print(\"Min = \", X_scale.min())\n",
    "print(\"Std = \", X_scale.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30351872",
   "metadata": {},
   "source": [
    "# Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730178b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = [['male', 'US', 'Safari'], ['female', 'Europe', 'Firefox'], ['female', 'Asia', 'Chrome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3621199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after OneHotEncoder transform : \n",
      " [[0.0 1.0 0.0 0.0 1.0 'Safari']\n",
      " [1.0 0.0 0.0 1.0 0.0 'Firefox']\n",
      " [1.0 0.0 1.0 0.0 0.0 'Chrome']]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Independent categorical data\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0, 1])], remainder='passthrough')\n",
    "\n",
    "X_encoded = ct.fit_transform(x_cat)\n",
    "print(\"after OneHotEncoder transform : \\n\", X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baa3be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after OrdinalEncoder transform : \n",
      " [[1.0 2.0 'Safari']\n",
      " [0.0 1.0 'Firefox']\n",
      " [0.0 0.0 'Chrome']]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Independent categorical data\n",
    "ct = ColumnTransformer(transformers=[('encoder', OrdinalEncoder(), [0, 1])], remainder='passthrough')\n",
    "\n",
    "X_encoded = ct.fit_transform(x_cat)\n",
    "print(\"after OrdinalEncoder transform : \\n\", X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3493687",
   "metadata": {},
   "source": [
    "# Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0bcb524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.169925  , 2.32192809, 3.9068906 , 4.169925  ],\n",
       "       [3.80735492, 4.        , 1.5849625 , 2.5849625 ],\n",
       "       [2.        , 1.5849625 , 0.        , 3.32192809],\n",
       "       [4.169925  , 3.9068906 , 3.80735492, 3.32192809]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = FunctionTransformer(np.log2)\n",
    "transformer.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
